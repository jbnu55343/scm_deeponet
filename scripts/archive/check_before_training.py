#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å¿«é€Ÿæ£€æŸ¥è„šæœ¬ - éªŒè¯æ˜¯å¦å¯ä»¥å¼€å§‹è®­ç»ƒ
"""

import sys
from pathlib import Path
import json

def check_files():
    """æ£€æŸ¥å¿…éœ€çš„æ–‡ä»¶"""
    print("=" * 70)
    print("ğŸ“‹ æ£€æŸ¥æ–‡ä»¶å®Œæ•´æ€§")
    print("=" * 70)
    
    files_to_check = [
        'train_mlp_speed.py',
        'postprocess_with_lags.py',
        'postprocess_with_lags_spatial.py',
        'network_spatial_features.py',
        '../data/dataset_sumo_5km_lag12_no_spatial.npz',
        '../data/dataset_sumo_5km_lag12_with_spatial.npz',
    ]
    
    all_exist = True
    for f in files_to_check:
        p = Path(f)
        exists = p.exists()
        status = "âœ“" if exists else "âœ—"
        print(f"  {status} {f}")
        if not exists:
            all_exist = False
    
    return all_exist


def check_data_quality():
    """æ£€æŸ¥æ•°æ®è´¨é‡"""
    print("\n" + "=" * 70)
    print("ğŸ“Š æ£€æŸ¥æ•°æ®è´¨é‡")
    print("=" * 70)
    
    try:
        import numpy as np
        
        for name, file in [
            ('Baseline', '../data/dataset_sumo_5km_lag12_no_spatial.npz'),
            ('Spatial', '../data/dataset_sumo_5km_lag12_with_spatial.npz'),
        ]:
            print(f"\n{name}:")
            
            try:
                data = np.load(file)
                X = data['X']
                Y = data['Y']
                
                print(f"  âœ“ æ–‡ä»¶å¯è¯»")
                print(f"    X å½¢çŠ¶: {X.shape}")
                print(f"    Y å½¢çŠ¶: {Y.shape}")
                
                # æ£€æŸ¥ NaN
                has_nan = np.isnan(X).any() or np.isnan(Y).any()
                print(f"    æ—  NaN: {'âœ— æœ‰ NaN' if has_nan else 'âœ“'}")
                
                # æ£€æŸ¥å…¨ 0 è¡Œ
                zero_rows = np.sum(np.sum(X, axis=(1, 2)) == 0)
                print(f"    å…¨ 0 è¡Œæ•°: {zero_rows} {'âŒ è­¦å‘Š' if zero_rows > 0 else 'âœ“'}")
                
                # æ£€æŸ¥å€¼åŸŸ
                print(f"    å€¼åŸŸ: [{X.min():.2f}, {X.max():.2f}]")
                
            except Exception as e:
                print(f"  âœ— é”™è¯¯: {e}")
    
    except ImportError:
        print("  âœ— numpy æœªå®‰è£…")


def check_dependencies():
    """æ£€æŸ¥ä¾èµ–"""
    print("\n" + "=" * 70)
    print("ğŸ“¦ æ£€æŸ¥ä¾èµ–")
    print("=" * 70)
    
    dependencies = ['numpy', 'torch']
    
    for dep in dependencies:
        try:
            __import__(dep)
            print(f"  âœ“ {dep}")
        except ImportError:
            print(f"  âœ— {dep} (éœ€è¦å®‰è£…: pip install {dep})")


def main():
    print("\n")
    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘                  è®­ç»ƒå‰å¿«é€Ÿæ£€æŸ¥                                  â•‘")
    print("â•‘              Check Before Starting Training                        â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n")
    
    files_ok = check_files()
    check_data_quality()
    check_dependencies()
    
    print("\n" + "=" * 70)
    
    if not files_ok:
        print("âŒ æŸäº›æ–‡ä»¶ç¼ºå¤±ï¼è¯·å…ˆè¿è¡Œï¼š")
        print("   python scripts/run_spatial_comparison.py")
        return False
    
    print("âœ… æ‰€æœ‰æ–‡ä»¶å°±ç»ªï¼")
    print("\nå¯ä»¥å¼€å§‹è®­ç»ƒäº†ï¼ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ï¼ˆåœ¨æ ¹ç›®å½•æ‰§è¡Œï¼‰ï¼š\n")
    
    print("1ï¸âƒ£  è®­ç»ƒ baseline ç‰ˆæœ¬:")
    print("   python scripts/train_mlp_speed.py --data data/dataset_sumo_5km_lag12_no_spatial.npz --epochs 100\n")
    
    print("2ï¸âƒ£  è®­ç»ƒ spatial ç‰ˆæœ¬:")
    print("   python scripts/train_mlp_speed.py --data data/dataset_sumo_5km_lag12_with_spatial.npz --epochs 100\n")
    
    print("=" * 70)
    return True


if __name__ == '__main__':
    success = main()
    sys.exit(0 if success else 1)
